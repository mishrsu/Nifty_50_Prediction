{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required LIBRARY\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "\n",
    "#importing LIBRARIES for LSTM model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import LSTM\n",
    "import plotly.graph_objects as go\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Required Datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating required dataset by appending data of past 10 years\n",
    "df_nifty50 = pd.read_csv('nifty50_2011.csv')\n",
    "LSTM_nifty50=df_nifty50['Close']\n",
    "df_nifty50 = pd.read_csv('nifty50_2012.csv')\n",
    "LSTM_closing=df_nifty50['Close']\n",
    "LSTM_nifty50 = LSTM_nifty50.append(LSTM_closing, ignore_index = True)\n",
    "df_nifty50 = pd.read_csv('nifty50_2013.csv')\n",
    "LSTM_closing=df_nifty50['Close']\n",
    "LSTM_nifty50 = LSTM_nifty50.append(LSTM_closing, ignore_index = True)\n",
    "df_nifty50 = pd.read_csv('nifty50_2014.csv')\n",
    "LSTM_closing=df_nifty50['Close']\n",
    "LSTM_nifty50 = LSTM_nifty50.append(LSTM_closing, ignore_index = True)\n",
    "df_nifty50 = pd.read_csv('nifty50_2015.csv')\n",
    "LSTM_closing=df_nifty50['Close']\n",
    "LSTM_nifty50 = LSTM_nifty50.append(LSTM_closing, ignore_index = True)\n",
    "df_nifty50 = pd.read_csv('nifty50_2016.csv')\n",
    "LSTM_closing=df_nifty50['Close']\n",
    "LSTM_nifty50 = LSTM_nifty50.append(LSTM_closing, ignore_index = True)\n",
    "df_nifty50 = pd.read_csv('nifty50_2017.csv')\n",
    "LSTM_closing=df_nifty50['Close']\n",
    "LSTM_nifty50 = LSTM_nifty50.append(LSTM_closing, ignore_index = True)\n",
    "df_nifty50 = pd.read_csv('nifty50_2018.csv')\n",
    "LSTM_closing=df_nifty50['Close']\n",
    "LSTM_nifty50 = LSTM_nifty50.append(LSTM_closing, ignore_index = True)\n",
    "df_nifty50 = pd.read_csv('nifty50_2019.csv')\n",
    "LSTM_closing=df_nifty50['Close']\n",
    "LSTM_nifty50 = LSTM_nifty50.append(LSTM_closing, ignore_index = True)\n",
    "df_nifty50 = pd.read_csv('nifty50_2020.csv')\n",
    "LSTM_closing=df_nifty50['Close']\n",
    "LSTM_nifty50 = LSTM_nifty50.append(LSTM_closing, ignore_index = True)\n",
    "df_nifty50 = pd.read_csv('nifty50_2021.csv')\n",
    "LSTM_closing=df_nifty50['Close']\n",
    "LSTM_nifty50 = LSTM_nifty50.append(LSTM_closing, ignore_index = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing plot for given data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the trend line for past 10 years of Nifty Index\n",
    "plt.figure(figsize = (10,5),dpi = 200)\n",
    "LSTM_nifty50.plot.line()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using MinMax scaler for tranforming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=LSTM_nifty50\n",
    "\n",
    "#using SKLEARN tranforming our data by using min max scaler function\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "df1_new=scaler.fit_transform(np.array(df2).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating training and testing data by splitting in 80% and 20%\n",
    "\n",
    "training_data,testing_data=df1_new[0:int(len(df1_new)*0.80),:],df1_new[int(len(df1_new)*0.80):len(df1_new),:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataset in the required form for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# converting the dataframe values into a matrix form of data\n",
    "def dataset_new(dataset, time_step=1):\n",
    "    Xinput = []\n",
    "    Yinput = []\n",
    "    range_len = len(dataset)-time_step\n",
    "    for i in range(range_len):\n",
    "        j = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100 \n",
    "        Xinput.append(j)\n",
    "        Yinput.append(dataset[i + time_step, 0])\n",
    "    return np.array(Xinput), np.array(Yinput) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dataset in X and y format using dataset_new funciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning value for time step\n",
    "time_step = 5\n",
    "\n",
    "#splitting the dataset in X and y form by using dataset_new function\n",
    "\n",
    "X_train, y_train = dataset_new(training_data, time_step)\n",
    "X_test, ytest = dataset_new(testing_data, time_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshaping the data in required form for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs1 = X_train.shape[0]\n",
    "xs2 = X_train.shape[1]\n",
    "xt1 = X_test.shape[0]\n",
    "xt2 = X_test.shape[1]\n",
    "\n",
    "\n",
    "#reshaping it into the format required by the LSTM model\n",
    "X_train =X_train.reshape(xs1,xs2, 1)\n",
    "X_test = X_test.reshape(xt1,xt2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using sequential model for our LSTM\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "#input layer\n",
    "model.add(LSTM(80,return_sequences=True,input_shape=(5,1)))\n",
    "\n",
    "#hidden layer 1\n",
    "model.add(LSTM(80,return_sequences=True))\n",
    "model.add(LSTM(80,return_sequences=True))\n",
    "model.add(LSTM(80,return_sequences=True))\n",
    "\n",
    "\n",
    "#hidden layer 2\n",
    "model.add(LSTM(80))\n",
    "\n",
    "\n",
    "\n",
    "#output layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "\n",
    "#compling all layer and use MSE as loss function\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using earlystopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining early stopping \n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing summary of LSTM model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fitting the model by using early stopping in callbacks and using X_testing as validation set\n",
    "\n",
    "model_fit=model.fit(X_train,y_train,validation_data=(X_test,ytest),epochs=200,batch_size=64,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicitng value by using Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Predicting training and testing dataset by model generated\n",
    "training_predict=model.predict(X_train)\n",
    "testing_predict=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining function for returning predicted and actual value for any dataset fed to it\n",
    "def predicting_value(filename):\n",
    "    df5 = pd.read_csv(filename)\n",
    "    df55 = df5['Close']\n",
    "    df5_new=scaler.transform(np.array(df55).reshape(-1,1))\n",
    "    \n",
    "    testing_data=df5_new[0:len(df5_new),:1]\n",
    "    \n",
    "    time_step = 5\n",
    "    X_test, ytest = dataset_new(testing_data, time_step)\n",
    "    xt1 = X_test.shape[0]\n",
    "    xt2 = X_test.shape[1]\n",
    "    X_test = X_test.reshape(xt1,xt2, 1)\n",
    "    tyu = model.predict(X_test)\n",
    "    tyu_ = scaler.inverse_transform(tyu)\n",
    "    tyu1 = tyu_.tolist()\n",
    "    tyu2 = np.arange(len(tyu1))\n",
    "\n",
    "    return df55[:-5],tyu1,tyu2\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename for which we are going to test the model\n",
    "filename = 'nifty50_test_2021.csv'\n",
    "\n",
    "#asssigning new variables to predicting_value function \n",
    "df55y = predicting_value(filename)[0]\n",
    "tyu1 = predicting_value(filename)[1]\n",
    "tyu2 = predicting_value(filename)[2];\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting prediction vs actual for any file with 'filename'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using interactive plot for plotting predicted value and actual value\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "ii = []\n",
    "for i in range(0,len(df55y)):\n",
    "    tyunew = tyu1[i][0]\n",
    "    i += 1\n",
    "    ii.append(tyunew)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig11=   go.Scatter(\n",
    "        x=tyu2,\n",
    "        y=ii,\n",
    "        name = \"prediction\"\n",
    "    )\n",
    "\n",
    "fig22  =  go.Scatter(\n",
    "        x=tyu2,\n",
    "        y=df55y,\n",
    "        name = \"actual\"\n",
    "    )\n",
    "\n",
    "data1 = [fig11,fig22]\n",
    "\n",
    "#style layout \n",
    "layout1 = go.Layout(\n",
    "    title=\"Nifty index Actual vs. Predicted\",\n",
    "    xaxis=dict(\n",
    "        title=\"Days\"\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=\"Nifty index\"\n",
    "    ) ) \n",
    "\n",
    "fig = go.Figure(data=data1, layout=layout1)\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming data to actual value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning new variables for reshaping\n",
    "ys1 =y_train.shape[0]\n",
    "yt1 = ytest.shape[0]\n",
    "y_train=y_train.reshape(ys1,1)\n",
    "y_test=ytest.reshape(yt1,1)\n",
    "\n",
    "# Using scaler function, transforming the entrie data back to original form\n",
    "train_pred=scaler.inverse_transform(training_predict)\n",
    "test_pred=scaler.inverse_transform(testing_predict)\n",
    "y_train_act=scaler.inverse_transform(y_train)\n",
    "y_test_act=scaler.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required LIBRARY for generating metrics\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "\n",
    "\n",
    "#defining function for Mean absolute precentage error\n",
    "def MAPE(y_true,y_pred):\n",
    "    mape=np.mean(np.abs(y_true-y_pred)/y_true)*100\n",
    "    return mape\n",
    "\n",
    "\n",
    "#calculating root mean squared error for train and test data\n",
    "RMSE1 = (math.sqrt(mean_squared_error(y_train_act,train_pred)))\n",
    "RMSE2 = (math.sqrt(mean_squared_error(y_test_act,test_pred)))\n",
    "\n",
    "#calculating mean absolute error for train and test data\n",
    "MAE1 = (mean_absolute_error(y_train_act,train_pred))\n",
    "MAE2 = (mean_absolute_error(y_test_act,test_pred))\n",
    "\n",
    "#calculating mean absolute precentage error for train and test data\n",
    "MAPE1 = (MAPE(y_train_act,train_pred))\n",
    "MAPE2 = (MAPE(y_test_act,test_pred))\n",
    "\n",
    "\n",
    "# import module for tabulating above data\n",
    "from tabulate import tabulate\n",
    "  \n",
    "# assign data\n",
    "mydata = [[\"RMSE_training\", RMSE1], [\"RMSE_test\", RMSE2],  [\"MAE_train\", MAE1],  [\"MAE_test\", MAE2], [\"MAPE_train%\", MAPE1], \n",
    "          [\"MAPE_test%\", MAPE2]]\n",
    "  \n",
    "# create header for values and metrics\n",
    "\n",
    "head = [\"Metric\", \"Value\"]\n",
    "\n",
    "# display table\n",
    "print(tabulate(mydata, headers=head, tablefmt=\"grid\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting Train loss and Test loss for epochs run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig1  = go.Scatter(\n",
    "        x=np.arange(len(model_fit.history['loss'])),\n",
    "        y=(model_fit.history['loss']),\n",
    "        name = \"train_loss\"\n",
    "    )\n",
    "\n",
    "fig2 =  go.Scatter(\n",
    "        x=np.arange(len(model_fit.history['loss'])),\n",
    "        y=(model_fit.history['val_loss']),\n",
    "        name = \"test_loss\"\n",
    "    )\n",
    "\n",
    "data = [fig1,fig2]\n",
    "#style layout \n",
    "layout = go.Layout(\n",
    "    title=\"LOSS vs epoch\",\n",
    "    xaxis=dict(\n",
    "        title=\"epoch\"\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=\"loss\"\n",
    "    ) ) \n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
